{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1f541a2-db18-490b-87a1-151fedcd8056",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/lydiaavin/Desktop/work/github-projects/genai-sandbox/.venv/lib/python3.10/site-packages (4.56.2)\n",
      "Requirement already satisfied: torch in /Users/lydiaavin/Desktop/work/github-projects/genai-sandbox/.venv/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: filelock in /Users/lydiaavin/Desktop/work/github-projects/genai-sandbox/.venv/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /Users/lydiaavin/Desktop/work/github-projects/genai-sandbox/.venv/lib/python3.10/site-packages (from transformers) (0.35.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/lydiaavin/Desktop/work/github-projects/genai-sandbox/.venv/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/lydiaavin/Desktop/work/github-projects/genai-sandbox/.venv/lib/python3.10/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/lydiaavin/Desktop/work/github-projects/genai-sandbox/.venv/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/lydiaavin/Desktop/work/github-projects/genai-sandbox/.venv/lib/python3.10/site-packages (from transformers) (2025.9.18)\n",
      "Requirement already satisfied: requests in /Users/lydiaavin/Desktop/work/github-projects/genai-sandbox/.venv/lib/python3.10/site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Users/lydiaavin/Desktop/work/github-projects/genai-sandbox/.venv/lib/python3.10/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/lydiaavin/Desktop/work/github-projects/genai-sandbox/.venv/lib/python3.10/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/lydiaavin/Desktop/work/github-projects/genai-sandbox/.venv/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/lydiaavin/Desktop/work/github-projects/genai-sandbox/.venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/lydiaavin/Desktop/work/github-projects/genai-sandbox/.venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/lydiaavin/Desktop/work/github-projects/genai-sandbox/.venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
      "Requirement already satisfied: sympy in /Users/lydiaavin/Desktop/work/github-projects/genai-sandbox/.venv/lib/python3.10/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /Users/lydiaavin/Desktop/work/github-projects/genai-sandbox/.venv/lib/python3.10/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/lydiaavin/Desktop/work/github-projects/genai-sandbox/.venv/lib/python3.10/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/lydiaavin/Desktop/work/github-projects/genai-sandbox/.venv/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/lydiaavin/Desktop/work/github-projects/genai-sandbox/.venv/lib/python3.10/site-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/lydiaavin/Desktop/work/github-projects/genai-sandbox/.venv/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/lydiaavin/Desktop/work/github-projects/genai-sandbox/.venv/lib/python3.10/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/lydiaavin/Desktop/work/github-projects/genai-sandbox/.venv/lib/python3.10/site-packages (from requests->transformers) (2025.8.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/lydiaavin/Desktop/work/github-projects/genai-sandbox/.venv/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "328bf4cf-f8d4-4ad7-b6fe-10a91422c2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: Hello\n",
      "French: Bonjour\n",
      "\n",
      "English: Hi, my name is Thomas\n",
      "French: Bonjour, mon nom est Thomas\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#direct model translation - no prompting\n",
    "from transformers import pipeline\n",
    "\n",
    "# English → French translation pipeline\n",
    "translator = pipeline(\"translation_en_to_fr\", model=\"t5-small\") #t5 handles translation directly\n",
    "\n",
    "sentences = [\n",
    "    \"Hello\",\n",
    "    \"Hi, my name is Thomas\"\n",
    "]\n",
    "\n",
    "for s in sentences:\n",
    "    translation = translator(s)\n",
    "    print(f\"English: {s}\")\n",
    "    print(f\"French: {translation[0]['translation_text']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ca1a8f8-3e32-4b07-b12b-73095a900022",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### GPT-2 Few-Shot Prompting ###\n",
      "\n",
      "\n",
      "Translate English to French:\n",
      "\n",
      "English: Hello, how are you?\n",
      "French: Bonjour, comment ça va ?\n",
      "\n",
      "English: Good morning\n",
      "French: Bonjour\n",
      "\n",
      "English: My name is Thomas\n",
      "French: Je m'appelle Thomas\n",
      "\n",
      "English: Hello\n",
      "French:\n",
      "\n",
      "French:\n",
      "\n",
      "French:\n",
      "\n",
      "French:\n",
      "\n",
      "French:\n",
      "\n",
      "French:\n",
      "\n",
      "French:\n",
      "\n",
      "French:\n",
      "\n",
      "French:\n",
      "\n",
      "French:\n",
      "\n",
      "French:\n",
      "\n",
      "French:\n",
      "\n",
      "French:\n",
      "\n",
      "French:\n",
      "\n",
      "French:\n",
      "\n",
      "French:\n",
      "\n",
      "French:\n",
      "\n",
      "French:\n",
      "\n",
      "French:\n",
      "\n",
      "French:\n",
      "\n",
      "French:\n",
      "\n",
      "French:\n",
      "\n",
      "French:\n",
      "\n",
      "French:\n",
      "\n",
      "French:\n",
      "\n",
      "French:\n",
      "\n",
      "French:\n",
      "\n",
      "French:\n",
      "\n",
      "French:\n",
      "\n",
      "French:\n",
      "\n",
      "French:\n",
      "\n",
      "French:\n",
      "\n",
      "French:\n",
      "\n",
      "French:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use GPT-style instruction model (GPT-2 or GPT-J)\n",
    "model_name = \"gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "few_shot_prompt = \"\"\"\n",
    "Translate English to French:\n",
    "\n",
    "English: Hello, how are you?\n",
    "French: Bonjour, comment ça va ?\n",
    "\n",
    "English: Good morning\n",
    "French: Bonjour\n",
    "\n",
    "English: My name is Thomas\n",
    "French: Je m'appelle Thomas\n",
    "\n",
    "English: Hello\n",
    "French:\n",
    "\"\"\"\n",
    "\n",
    "inputs = tokenizer(few_shot_prompt, return_tensors=\"pt\")\n",
    "outputs = model.generate(**inputs, max_length=200)\n",
    "print(\"### GPT-2 Few-Shot Prompting ###\\n\")\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e586ba7-9585-4495-b7eb-2bc537ce174e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solve this math problem step by step: 20 * 4 = 2.5 * (2.5 + 1.5) * (2.5 + 1.5) * (2.5 + 1.5) * (2.5 + 1.5) * (2.5 + 1.5) * (2.5 + 1.5) * (2.5 + 1.5) * (2.5 + 1.5) * (2.\n"
     ]
    }
   ],
   "source": [
    "# Chain of Thought Prompting\n",
    "cot_prompt = \"Solve this math problem step by step: 20 * 4 =\"\n",
    "\n",
    "inputs = tokenizer(cot_prompt, return_tensors=\"pt\")\n",
    "outputs = model.generate(**inputs, max_length=100)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4db007-0aee-479b-92f3-781d200a0fea",
   "metadata": {},
   "source": [
    "# Observations:\n",
    "\n",
    "## Few-Shot Prompting:\n",
    "1. GPT-2 is not instruction-tuned; may repeat or give wrong translations.  \n",
    "2. Few-shot examples guide output but results are not perfect.  \n",
    "3. Use T5, mBART, or GPT-3/3.5 for accurate translations.\n",
    "\n",
    "## Chain-of-Thought:\n",
    "1. Encourages step-by-step reasoning, but GPT-2 may be inaccurate.  \n",
    "2. Instruction-tuned LLMs give more reliable CoT outputs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
